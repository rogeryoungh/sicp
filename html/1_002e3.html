<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<!-- Created by GNU Texinfo 6.7, http://www.gnu.org/software/texinfo/ -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>1.3 (Structure and Interpretation of Computer Programs, 2e)</title>

<meta name="description" content="1.3 (Structure and Interpretation of Computer Programs, 2e)">
<meta name="keywords" content="1.3 (Structure and Interpretation of Computer Programs, 2e)">
<meta name="resource-type" content="document">
<meta name="distribution" content="global">
<meta name="Generator" content="texi2any">
<link href="index.html" rel="start" title="Top">
<link href="Term-Index.html" rel="index" title="Term Index">
<link href="index.html#SEC_Contents" rel="contents" title="Table of Contents">
<link href="Chapter-1.html" rel="up" title="Chapter 1">
<link href="Chapter-2.html" rel="next" title="Chapter 2">
<link href="1_002e2.html#g_t1_002e2_002e6" rel="prev" title="1.2.6">
<style type="text/css">
<!--
a.summary-letter {text-decoration: none}
blockquote.indentedblock {margin-right: 0em}
div.display {margin-left: 3.2em}
div.example {margin-left: 3.2em}
div.lisp {margin-left: 3.2em}
kbd {font-style: oblique}
pre.display {font-family: inherit}
pre.format {font-family: inherit}
pre.menu-comment {font-family: serif}
pre.menu-preformatted {font-family: serif}
span.nolinebreak {white-space: nowrap}
span.roman {font-family: initial; font-weight: normal}
span.sansserif {font-family: sans-serif; font-weight: normal}
ul.no-bullet {list-style: none}
-->
</style>

<link href="css/style.css" rel="stylesheet" type="text/css" />
<link href="css/prettify.css" rel="stylesheet" type="text/css" />

<script class="prettifier" src="js/highlight/prettify.js" type="text/javascript"></script>
<script class="prettifier" src="js/highlight/lang-lisp.js" type="text/javascript"></script>

<script src="js/jquery.min.js" type="text/javascript"></script>
<script src="js/footnotes.js" type="text/javascript"></script>
<script src="js/browsertest.js" type="text/javascript"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js" type="text/javascript"></script>
</head>

<body lang="en">
<section><span class="top jump" title="Jump to top"><a href="#pagetop" accesskey="t">&#8673;</a></span><a id="pagetop"></a><span id="g_t1_002e3"></span><div class="header">
<p>
Next: <a href="Chapter-2.html" accesskey="n" rel="next">Chapter 2</a>, Previous: <a href="1_002e2.html#g_t1_002e2" accesskey="p" rel="prev">1.2</a>, Up: <a href="Chapter-1.html" accesskey="u" rel="up">Chapter 1</a> &nbsp; [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Term-Index.html" title="Index" rel="index">Index</a>]</p>
</div>
<span id="Formulating-Abstractions-with-Higher_002dOrder-Procedures"></span><h3 class="section"><span class="secnum">1.3</span><span class="sectitle">Formulating Abstractions with Higher-Order Procedures</span></h3>

<p>We have seen that procedures are, in effect, abstractions that describe
compound operations on numbers independent of the particular numbers.  For
example, when we
</p>
<div class="lisp">
<pre class="lisp">(define (cube x) (* x x x))
</pre></div>

<p>we are not talking about the cube of a particular number, but rather about a
method for obtaining the cube of any number.  Of course we could get along
without ever defining this procedure, by always writing expressions such as
</p>
<div class="lisp">
<pre class="lisp">(* 3 3 3)
(* x x x)
(* y y y)
</pre></div>

<p>and never mentioning <code>cube</code> explicitly.  This would place us at a serious
disadvantage, forcing us to work always at the level of the particular
operations that happen to be primitives in the language (multiplication, in
this case) rather than in terms of higher-level operations.  Our programs would
be able to compute cubes, but our language would lack the ability to express
the concept of cubing.  One of the things we should demand from a powerful
programming language is the ability to build abstractions by assigning names to
common patterns and then to work in terms of the abstractions directly.
Procedures provide this ability.  This is why all but the most primitive
programming languages include mechanisms for defining procedures.
</p>
<p>Yet even in numerical processing we will be severely limited in our ability to
create abstractions if we are restricted to procedures whose parameters must be
numbers.  Often the same programming pattern will be used with a number of
different procedures.  To express such patterns as concepts, we will need to
construct procedures that can accept procedures as arguments or return
procedures as values.  Procedures that manipulate procedures are called
<span id="index-higher_002dorder-procedures"></span>
<em>higher-order procedures</em>.  This section shows how higher-order
procedures can serve as powerful abstraction mechanisms, vastly increasing the
expressive power of our language.
</p>

<hr>
<span id="g_t1_002e3_002e1"></span><span id="Procedures-as-Arguments"></span><h4 class="subsection"><span class="secnum">1.3.1</span><span class="sectitle">Procedures as Arguments</span></h4>

<p>Consider the following three procedures.  The first computes the sum of the
integers from <code>a</code> through <code>b</code>:
</p>
<div class="lisp">
<pre class="lisp">(define (sum-integers a b)
  (if (&gt; a b) 
      0 
      (+ a (sum-integers (+ a 1) b))))
</pre></div>

<p>The second computes the sum of the cubes of the integers in the given range:
</p>
<div class="lisp">
<pre class="lisp">(define (sum-cubes a b)
  (if (&gt; a b) 
      0 
      (+ (cube a) 
         (sum-cubes (+ a 1) b))))
</pre></div>

<p>The third computes the sum of a sequence of terms in the series

\[ % :17:
  
\frac{1}{1\cdot 3} +  \frac{1}{5\cdot 7} + \frac{1}{9\cdot 11} + {\dots,}
\]

which converges to \( {\pi / 8} \) (very slowly):<a class="footnote_link" id="DOCF49" href="#FOOT49"><sup>49</sup></a>
</p>
<div class="lisp">
<pre class="lisp">(define (pi-sum a b)
  (if (&gt; a b)
      0
      (+ (/ 1.0 (* a (+ a 2))) 
         (pi-sum (+ a 4) b))))
</pre></div>

<p>These three procedures clearly share a common underlying pattern.  They are for
the most part identical, differing only in the name of the procedure, the
function of <code>a</code> used to compute the term to be added, and the function
that provides the next value of <code>a</code>.  We could generate each of the
procedures by filling in slots in the same template:
</p>
<div class="lisp">
<pre class="lisp">(define (⟨<var>name</var>⟩ a b)
  (if (&gt; a b)
      0
      (+ (⟨<var>term</var>⟩ a) 
         (⟨<var>name</var>⟩ (⟨<var>next</var>⟩ a) b))))
</pre></div>

<p>The presence of such a common pattern is strong evidence that there is a useful
abstraction waiting to be brought to the surface.  Indeed, mathematicians long
ago identified the abstraction of <span id="index-summation-of-a-series"></span>
<em>summation of a series</em> and invented
&ldquo;sigma notation,&rdquo; for example

\[ % :18:
 
{\sum_{n = a}^b f(n)} \,=\, {f(a)} + \dots + {f(b),}
\]

to express this concept.  The power of sigma notation is that it allows
mathematicians to deal with the concept of summation itself rather than only
with particular sums&mdash;for example, to formulate general results about sums
that are independent of the particular series being summed.
</p>
<p>Similarly, as program designers, we would like our language to be powerful
enough so that we can write a procedure that expresses the concept of summation
itself rather than only procedures that compute particular sums.  We can do so
readily in our procedural language by taking the common template shown above
and transforming the &ldquo;slots&rdquo; into formal parameters:
</p>
<div class="lisp">
<pre class="lisp">(define (sum term a next b)
  (if (&gt; a b)
      0
      (+ (term a)
         (sum term (next a) next b))))
</pre></div>

<p>Notice that <code>sum</code> takes as its arguments the lower and upper bounds
<code>a</code> and <code>b</code> together with the procedures <code>term</code> and <code>next</code>.
We can use <code>sum</code> just as we would any procedure.  For example, we can use
it (along with a procedure <code>inc</code> that increments its argument by 1) to
define <code>sum-cubes</code>:
</p>
<div class="lisp">
<pre class="lisp">(define (inc n) (+ n 1))

(define (sum-cubes a b)
  (sum cube a inc b))
</pre></div>

<p>Using this, we can compute the sum of the cubes of the integers from 1 to 10:
</p>
<div class="lisp">
<pre class="lisp">(sum-cubes 1 10)
<i>3025</i>
</pre></div>

<p>With the aid of an identity procedure to compute the term, we can define
<code>sum-integers</code> in terms of <code>sum</code>:
</p>
<div class="lisp">
<pre class="lisp">(define (identity x) x)

(define (sum-integers a b)
  (sum identity a inc b))
</pre></div>

<p>Then we can add up the integers from 1 to 10:
</p>
<div class="lisp">
<pre class="lisp">(sum-integers 1 10)
<i>55</i>
</pre></div>

<p>We can also define <code>pi-sum</code> in the same way:<a class="footnote_link" id="DOCF50" href="#FOOT50"><sup>50</sup></a>
</p>
<div class="lisp">
<pre class="lisp">(define (pi-sum a b)
  (define (pi-term x)
    (/ 1.0 (* x (+ x 2))))
  (define (pi-next x)
    (+ x 4))
  (sum pi-term a pi-next b))
</pre></div>

<p>Using these procedures, we can compute an approximation to \( \pi \):
</p>
<div class="lisp">
<pre class="lisp">(* 8 (pi-sum 1 1000))
<i>3.139592655589783</i>
</pre></div>

<p>Once we have <code>sum</code>, we can use it as a building block in formulating
further concepts.  For instance, the definite integral of a function \( f \)
between the limits \( a \) and \( b \) can be approximated numerically using the
formula

\[ % :19:
 
{\int_a^b \kern-0.3em f}
  \;=\; {\left[\;f\left(a + \frac{d x}{2}\right)\right.}
  \,+\, {f\left(a + dx + \frac{dx}{2}\right)}
  \,+\, {\left. f\left(a + 2dx + \frac{dx}{2}\right)
  \,+\, \dots \;\right] dx}
\]

for small values of \( {dx} \).  We can express this directly as a procedure:
</p>
<div class="lisp">
<pre class="lisp">(define (integral f a b dx)
  (define (add-dx x) (+ x dx))
  (* (sum f (+ a (/ dx 2.0)) add-dx b) 
     dx))

(integral cube 0 1 0.01)
<i>.24998750000000042</i>

(integral cube 0 1 0.001)
<i>.249999875000001</i>
</pre></div>

<p>(The exact value of the integral of <code>cube</code> between 0 and 1 is 1/4.)
</p>
<blockquote>
<p><strong><span id="Exercise-1_002e29"></span>Exercise 1.29:</strong> Simpson&rsquo;s Rule is a more accurate
method of numerical integration than the method illustrated above.  Using
Simpson&rsquo;s Rule, the integral of a function \( f \) between \( a \) and \( b \) is
approximated as

\[ % :20:
  
\frac{h}{3}(y_0 + {4y_1} + {2y_2} + {4y_3} + {2y_4} + \dots + {2y_{n-2}} + {4y_{n-1} + y_n),}
\]

where \( {h = (b - a)/n} \), for some even integer \( n \), and
\( y_k = {f(a + kh)} \).  (Increasing \( n \) increases the
accuracy of the approximation.)  Define a procedure that takes as arguments
\( f \), \( a \), \( b \), and \( n \) and returns the value of the integral, computed
using Simpson&rsquo;s Rule.  Use your procedure to integrate <code>cube</code> between 0
and 1 (with \( {n = 100} \) and \( {n = 1000} \)), and compare the results to those of
the <code>integral</code> procedure shown above.
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e30"></span>Exercise 1.30:</strong> The <code>sum</code> procedure above
generates a linear recursion.  The procedure can be rewritten so that the sum
is performed iteratively.  Show how to do this by filling in the missing
expressions in the following definition:
</p>
<div class="lisp">
<pre class="lisp">(define (sum term a next b)
  (define (iter a result)
    (if ⟨??⟩
        ⟨??⟩
        (iter ⟨??⟩ ⟨??⟩)))
  (iter ⟨??⟩ ⟨??⟩))
</pre></div>
</blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e31"></span>Exercise 1.31:</strong> 
</p>
<ol type="a" start="1">
<li> The <code>sum</code> procedure is only the simplest of a vast number of similar
abstractions that can be captured as higher-order procedures.<a class="footnote_link" id="DOCF51" href="#FOOT51"><sup>51</sup></a>  Write an analogous
procedure called <code>product</code> that returns the product of the values of a
function at points over a given range.  Show how to define <code>factorial</code> in
terms of <code>product</code>.  Also use <code>product</code> to compute approximations to
\( \pi \) using the formula<a class="footnote_link" id="DOCF52" href="#FOOT52"><sup>52</sup></a>

\[ % :21:
  
\frac{\pi}{4} \,=\, {\frac{2\cdot 4\cdot 4\cdot 6\cdot 6\cdot 8\cdot\cdots}
                     {3\cdot 3\cdot 5\cdot 5\cdot 7\cdot 7\cdot\cdots}.}
\]

</li><li> If your <code>product</code> procedure generates a recursive process, write one that
generates an iterative process.  If it generates an iterative process, write
one that generates a recursive process.

</li></ol>
</blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e32"></span>Exercise 1.32:</strong> 
</p>
<ol type="a" start="1">
<li> Show that <code>sum</code> and <code>product</code> (<a href="#Exercise-1_002e31">Exercise 1.31</a>) are both special
cases of a still more general notion called <code>accumulate</code> that combines a
collection of terms, using some general accumulation function:

<div class="lisp">
<pre class="lisp">(accumulate 
 combiner null-value term a next b)
</pre></div>

<p><code>Accumulate</code> takes as arguments the same term and range specifications as
<code>sum</code> and <code>product</code>, together with a <code>combiner</code> procedure (of
two arguments) that specifies how the current term is to be combined with the
accumulation of the preceding terms and a <code>null-value</code> that specifies what
base value to use when the terms run out.  Write <code>accumulate</code> and show how
<code>sum</code> and <code>product</code> can both be defined as simple calls to
<code>accumulate</code>.
</p>
</li><li> If your <code>accumulate</code> procedure generates a recursive process, write one
that generates an iterative process.  If it generates an iterative process,
write one that generates a recursive process.

</li></ol>
</blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e33"></span>Exercise 1.33:</strong> You can obtain an even more
general version of <code>accumulate</code> (<a href="#Exercise-1_002e32">Exercise 1.32</a>) by introducing the
notion of a <span id="index-filter"></span>
<em>filter</em> on the terms to be combined.  That is, combine
only those terms derived from values in the range that satisfy a specified
condition.  The resulting <code>filtered-accumulate</code> abstraction takes the same
arguments as accumulate, together with an additional predicate of one argument
that specifies the filter.  Write <code>filtered-accumulate</code> as a procedure.
Show how to express the following using <code>filtered-accumulate</code>:
</p>
<ol type="a" start="1">
<li> the sum of the squares of the prime numbers in the interval \( a \) to \( b \)
(assuming that you have a <code>prime?</code> predicate already written)

</li><li> the product of all the positive integers less than \( n \) that are relatively
prime to \( n \) (i.e., all positive integers \( {i &lt; n} \) such that
\( {\text{GCD}(i, n) = 1} \)).

</li></ol>
</blockquote>

<hr>
<span id="g_t1_002e3_002e2"></span><span id="Constructing-Procedures-Using-Lambda"></span><h4 class="subsection"><span class="secnum">1.3.2</span><span class="sectitle">Constructing Procedures Using <code>Lambda</code></span></h4>

<p>In using <code>sum</code> as in <a href="#g_t1_002e3_002e1">1.3.1</a>, it seems terribly awkward to
have to define trivial procedures such as <code>pi-term</code> and <code>pi-next</code>
just so we can use them as arguments to our higher-order procedure.  Rather
than define <code>pi-next</code> and <code>pi-term</code>, it would be more convenient to
have a way to directly specify &ldquo;the procedure that returns its input
incremented by 4&rdquo; and &ldquo;the procedure that returns the reciprocal of its input
times its input plus 2.&rdquo;  We can do this by introducing the special form
<code>lambda</code>, which creates procedures.  Using <code>lambda</code> we can describe
what we want as
</p>
<div class="lisp">
<pre class="lisp">(lambda (x) (+ x 4))
</pre></div>

<p>and
</p>
<div class="lisp">
<pre class="lisp">(lambda (x) (/ 1.0 (* x (+ x 2))))
</pre></div>

<p>Then our <code>pi-sum</code> procedure can be expressed without defining any
auxiliary procedures as
</p>
<div class="lisp">
<pre class="lisp">(define (pi-sum a b)
  (sum (lambda (x) (/ 1.0 (* x (+ x 2))))
       a
       (lambda (x) (+ x 4))
       b))
</pre></div>

<p>Again using <code>lambda</code>, we can write the <code>integral</code> procedure without
having to define the auxiliary procedure <code>add-dx</code>:
</p>
<div class="lisp">
<pre class="lisp">(define (integral f a b dx)
  (* (sum f (+ a (/ dx 2.0))
            (lambda (x) (+ x dx))
            b)
     dx))
</pre></div>

<p>In general, <code>lambda</code> is used to create procedures in the same way as
<code>define</code>, except that no name is specified for the procedure:
</p>
<div class="lisp">
<pre class="lisp">(lambda (⟨<var>formal-parameters</var>⟩) ⟨<var>body</var>⟩)
</pre></div>

<p>The resulting procedure is just as much a procedure as one that is created
using <code>define</code>.  The only difference is that it has not been associated
with any name in the environment.  In fact,
</p>
<div class="lisp">
<pre class="lisp">(define (plus4 x) (+ x 4))
</pre></div>

<p>is equivalent to
</p>
<div class="lisp">
<pre class="lisp">(define plus4 (lambda (x) (+ x 4)))
</pre></div>

<p>We can read a <code>lambda</code> expression as follows:
</p>
<div class="example">
<pre class="example">(lambda                     (x)     (+   x     4))
    |                        |       |   |     |
the procedure of an argument x that adds x and 4
</pre></div>

<p>Like any expression that has a procedure as its value, a <code>lambda</code>
expression can be used as the operator in a combination such as
</p>
<div class="lisp">
<pre class="lisp">((lambda (x y z) (+ x y (square z))) 1 2 3)
<i>12</i>
</pre></div>

<p>or, more generally, in any context where we would normally use a procedure
name.<a class="footnote_link" id="DOCF53" href="#FOOT53"><sup>53</sup></a>
</p>
<span id="Using-let-to-create-local-variables"></span><h4 class="subsubheading">Using <code>let</code> to create local variables</h4>

<p>Another use of <code>lambda</code> is in creating local variables.  We often need
local variables in our procedures other than those that have been bound as
formal parameters.  For example, suppose we wish to compute the function

\[ % :22:
  
{f(x,y)} \,=\, {x(1 + xy)^2} + {y(1 - y)} + {(1 + xy)(1 - y),}
\]

which we could also express as

\[ % :23:
 
\begin{eqnarray}
  a                     &amp;=&amp;   {1 + xy,}  \\
  \hphantom{(x,y)} b    &amp;=&amp;   {1 - y,}   \\
  {f(x,y)}              &amp;=&amp;   {xa^2} + {yb} + {ab.}
\end{eqnarray}
\]

In writing a procedure to compute \( f \), we would like to include as local
variables not only \( x \) and \( y \) but also the names of intermediate
quantities like \( a \) and \( b \).  One way to accomplish this is to use an
auxiliary procedure to bind the local variables:
</p>
<div class="lisp">
<pre class="lisp">(define (f x y)
  (define (f-helper a b)
    (+ (* x (square a))
       (* y b)
       (* a b)))
  (f-helper (+ 1 (* x y)) 
            (- 1 y)))
</pre></div>

<p>Of course, we could use a <code>lambda</code> expression to specify an anonymous
procedure for binding our local variables.  The body of <code>f</code> then becomes a
single call to that procedure:
</p>
<div class="lisp">
<pre class="lisp">(define (f x y)
  ((lambda (a b)
     (+ (* x (square a)) 
        (* y b) 
        (* a b)))
   (+ 1 (* x y))
   (- 1 y)))
</pre></div>

<p>This construct is so useful that there is a special form called <code>let</code> to
make its use more convenient.  Using <code>let</code>, the <code>f</code> procedure could
be written as
</p>
<div class="lisp">
<pre class="lisp">(define (f x y)
  (let ((a (+ 1 (* x y)))
        (b (- 1 y)))
    (+ (* x (square a))
       (* y b)
       (* a b))))
</pre></div>

<p>The general form of a <code>let</code> expression is
</p>
<div class="lisp">
<pre class="lisp">(let ((⟨<var>var₁</var>⟩ ⟨<var>exp₁</var>⟩)
      (⟨<var>var₂</var>⟩ ⟨<var>exp₂</var>⟩)
      <span class="roman">…</span>
      (⟨<var>varₙ</var>⟩ ⟨<var>expₙ</var>⟩))
  ⟨<var>body</var>⟩)
</pre></div>

<p>which can be thought of as saying
</p>
<div class="example">
<pre class="example">let ⟨<var>var₁</var>⟩ <span class="roman">have the value</span> ⟨<var>exp₁</var>⟩ <span class="roman">and</span>
    ⟨<var>var₂</var>⟩ <span class="roman">have the value</span> ⟨<var>exp₂</var>⟩ <span class="roman">and</span>
    <span class="roman">…</span>
    ⟨<var>varₙ</var>⟩ <span class="roman">have the value</span> ⟨<var>expₙ</var>⟩
  <span class="roman">in</span> ⟨<var>body</var>⟩
</pre></div>

<p>The first part of the <code>let</code> expression is a list of name-expression pairs.
When the <code>let</code> is evaluated, each name is associated with the value of the
corresponding expression.  The body of the <code>let</code> is evaluated with these
names bound as local variables.  The way this happens is that the <code>let</code>
expression is interpreted as an alternate syntax for
</p>
<div class="lisp">
<pre class="lisp">((lambda (⟨<var>var₁</var>⟩ <span class="roman">…</span> ⟨<var>varₙ</var>⟩)
   ⟨<var>body</var>⟩)
 ⟨<var>exp₁</var>⟩
 <span class="roman">…</span>
 ⟨<var>expₙ</var>⟩)
</pre></div>

<p>No new mechanism is required in the interpreter in order to provide local
variables.  A <code>let</code> expression is simply syntactic sugar for the
underlying <code>lambda</code> application.
</p>
<p>We can see from this equivalence that the scope of a variable specified by a
<code>let</code> expression is the body of the <code>let</code>.  This implies that:
</p>
<ul>
<li> <code>Let</code> allows one to bind variables as locally as possible to where they
are to be used.  For example, if the value of <code>x</code> is 5, the value of the
expression

<div class="lisp">
<pre class="lisp">(+ (let ((x 3))
     (+ x (* x 10)))
   x)
</pre></div>

<p>is 38.  Here, the <code>x</code> in the body of the <code>let</code> is 3, so the value of
the <code>let</code> expression is 33.  On the other hand, the <code>x</code> that is the
second argument to the outermost <code>+</code> is still 5.
</p>
</li><li> The variables&rsquo; values are computed outside the <code>let</code>.  This matters when
the expressions that provide the values for the local variables depend upon
variables having the same names as the local variables themselves.  For
example, if the value of <code>x</code> is 2, the expression

<div class="lisp">
<pre class="lisp">(let ((x 3)
      (y (+ x 2)))
  (* x y))
</pre></div>

<p>will have the value 12 because, inside the body of the <code>let</code>, <code>x</code>
will be 3 and <code>y</code> will be 4 (which is the outer <code>x</code> plus 2).
</p>
</li></ul>

<p>Sometimes we can use internal definitions to get the same effect as with
<code>let</code>.  For example, we could have defined the procedure <code>f</code> above as
</p>
<div class="lisp">
<pre class="lisp">(define (f x y)
  (define a 
    (+ 1 (* x y)))
  (define b (- 1 y))
  (+ (* x (square a))
     (* y b)
     (* a b)))
</pre></div>

<p>We prefer, however, to use <code>let</code> in situations like this and to use
internal <code>define</code> only for internal procedures.<a class="footnote_link" id="DOCF54" href="#FOOT54"><sup>54</sup></a>
</p>
<blockquote>
<p><strong><span id="Exercise-1_002e34"></span>Exercise 1.34:</strong> Suppose we define the procedure
</p>
<div class="lisp">
<pre class="lisp">(define (f g) (g 2))
</pre></div>

<p>Then we have
</p>
<div class="lisp">
<pre class="lisp">(f square)
<i>4</i>

(f (lambda (z) (* z (+ z 1))))
<i>6</i>
</pre></div>

<p>What happens if we (perversely) ask the interpreter to evaluate the combination
<code>(f f)</code>?  Explain.
</p></blockquote>

<hr>
<span id="g_t1_002e3_002e3"></span><span id="Procedures-as-General-Methods"></span><h4 class="subsection"><span class="secnum">1.3.3</span><span class="sectitle">Procedures as General Methods</span></h4>

<p>We introduced compound procedures in <a href="1_002e1.html#g_t1_002e1_002e4">1.1.4</a> as a mechanism for
abstracting patterns of numerical operations so as to make them independent of
the particular numbers involved.  With higher-order procedures, such as the
<code>integral</code> procedure of <a href="#g_t1_002e3_002e1">1.3.1</a>, we began to see a more
powerful kind of abstraction: procedures used to express general methods of
computation, independent of the particular functions involved.  In this section
we discuss two more elaborate examples&mdash;general methods for finding zeros and
fixed points of functions&mdash;and show how these methods can be expressed
directly as procedures.
</p>
<span id="Finding-roots-of-equations-by-the-half_002dinterval-method"></span><h4 class="subsubheading">Finding roots of equations by the half-interval method</h4>

<p>The <span id="index-half_002dinterval-method"></span>
<em>half-interval method</em> is a simple but powerful technique for
finding roots of an equation \( {f(x) = 0} \), where \( f \) is a continuous
function.  The idea is that, if we are given points \( a \) and \( b \) such that
\( {f(a) &lt; 0 &lt; f(b)} \), then \( f \) must have at least one zero between
\( a \) and \( b \).  To locate a zero, let \( x \) be the average of \( a \) and \( b \),
and compute \( {f(x)} \).  If \( {f(x) &gt; 0} \), then \( f \) must have a zero
between \( a \) and \( x \).  If \( {f(x) &lt; 0} \), then \( f \) must have a zero
between \( x \) and \( b \).  Continuing in this way, we can identify smaller and
smaller intervals on which \( f \) must have a zero.  When we reach a point where
the interval is small enough, the process stops.  Since the interval of
uncertainty is reduced by half at each step of the process, the number of steps
required grows as \( {\Theta(\log(L\, /\, T))} \), where \( L \) is the
length of the original interval and \( T \) is the error tolerance (that is, the
size of the interval we will consider &ldquo;small enough&rdquo;).  Here is a procedure
that implements this strategy:
</p>
<div class="lisp">
<pre class="lisp">(define (search f neg-point pos-point)
  (let ((midpoint 
         (average neg-point pos-point)))
    (if (close-enough? neg-point pos-point)
        midpoint
        (let ((test-value (f midpoint)))
          (cond 
           ((positive? test-value)
            (search f neg-point midpoint))
           ((negative? test-value)
            (search f midpoint pos-point))
           (else midpoint))))))
</pre></div>

<p>We assume that we are initially given the function \( f \) together with points
at which its values are negative and positive.  We first compute the midpoint
of the two given points.  Next we check to see if the given interval is small
enough, and if so we simply return the midpoint as our answer.  Otherwise, we
compute as a test value the value of \( f \) at the midpoint.  If the test value
is positive, then we continue the process with a new interval running from the
original negative point to the midpoint.  If the test value is negative, we
continue with the interval from the midpoint to the positive point.  Finally,
there is the possibility that the test value is 0, in which case the midpoint
is itself the root we are searching for.
</p>
<p>To test whether the endpoints are &ldquo;close enough&rdquo; we can use a procedure
similar to the one used in <a href="1_002e1.html#g_t1_002e1_002e7">1.1.7</a> for computing square
roots:<a class="footnote_link" id="DOCF55" href="#FOOT55"><sup>55</sup></a>
</p>
<div class="lisp">
<pre class="lisp">(define (close-enough? x y) 
  (&lt; (abs (- x y)) 0.001))
</pre></div>

<p><code>Search</code> is awkward to use directly, because we can accidentally give it
points at which \( f \)&rsquo;s values do not have the required sign, in which case we
get a wrong answer.  Instead we will use <code>search</code> via the following
procedure, which checks to see which of the endpoints has a negative function
value and which has a positive value, and calls the <code>search</code> procedure
accordingly.  If the function has the same sign on the two given points, the
half-interval method cannot be used, in which case the procedure signals an
error.<a class="footnote_link" id="DOCF56" href="#FOOT56"><sup>56</sup></a>
</p>
<div class="lisp">
<pre class="lisp">(define (half-interval-method f a b)
  (let ((a-value (f a))
        (b-value (f b)))
    (cond ((and (negative? a-value) 
                (positive? b-value))
           (search f a b))
          ((and (negative? b-value) 
                (positive? a-value))
           (search f b a))
          (else
           (error &quot;Values are not of 
                   opposite sign&quot; a b)))))
</pre></div>

<p>The following example uses the half-interval method to approximate \( \pi \) as
the root between 2 and 4 of \( {\sin x = 0} \):
</p>
<div class="lisp">
<pre class="lisp">(half-interval-method sin 2.0 4.0)
<i>3.14111328125</i>
</pre></div>

<p>Here is another example, using the half-interval method to search for a root of
the equation \( {x^3 - 2x - 3 = 0} \) between 1 and 2:
</p>
<div class="lisp">
<pre class="lisp">(half-interval-method 
 (lambda (x) (- (* x x x) (* 2 x) 3))
 1.0
 2.0)
<i>1.89306640625</i>
</pre></div>

<span id="Finding-fixed-points-of-functions"></span><h4 class="subsubheading">Finding fixed points of functions</h4>

<p>A number \( x \) is called a <span id="index-fixed-point"></span>
<em>fixed point</em> of a function \( f \) if \( x \)
satisfies the equation \( {f(x) = x} \).  For some functions \( f \) we can
locate a fixed point by beginning with an initial guess and applying \( f \)
repeatedly,

\[ % :24:
  
{f(x),}\quad {f(f(x)),}\quad {f(f(f(x))),} \quad{\dots,}
\]

until the value does not change very much.  Using this idea, we can devise a
procedure <code>fixed-point</code> that takes as inputs a function and an initial
guess and produces an approximation to a fixed point of the function.  We apply
the function repeatedly until we find two successive values whose difference is
less than some prescribed tolerance:
</p>
<div class="lisp">
<pre class="lisp">(define tolerance 0.00001)

(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (&lt; (abs (- v1 v2)) 
       tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))
</pre></div>

<p>For example, we can use this method to approximate the fixed point of the
cosine function, starting with 1 as an initial approximation:<a class="footnote_link" id="DOCF57" href="#FOOT57"><sup>57</sup></a>
</p>
<div class="lisp">
<pre class="lisp">(fixed-point cos 1.0)
<i>.7390822985224023</i>
</pre></div>

<p>Similarly, we can find a solution to the equation 
\( {y = \sin y + \cos y} \):
</p>
<div class="lisp">
<pre class="lisp">(fixed-point (lambda (y) (+ (sin y) (cos y)))
             1.0)
<i>1.2587315962971173</i>
</pre></div>

<p>The fixed-point process is reminiscent of the process we used for finding
square roots in <a href="1_002e1.html#g_t1_002e1_002e7">1.1.7</a>.  Both are based on the idea of repeatedly
improving a guess until the result satisfies some criterion.  In fact, we can
readily formulate the square-root computation as a fixed-point search.
Computing the square root of some number \( x \) requires finding a \( y \) such
that \( {y^2 = x} \).  Putting this equation into the equivalent form 
\( {y = x / y} \), we recognize that we are looking for a fixed point of the
function<a class="footnote_link" id="DOCF58" href="#FOOT58"><sup>58</sup></a> \( {y \mapsto x / y} \), 
and we can therefore try to compute square roots as
</p>
<div class="lisp">
<pre class="lisp">(define (sqrt x)
  (fixed-point (lambda (y) (/ x y))
               1.0))
</pre></div>

<p>Unfortunately, this fixed-point search does not converge.  Consider an initial
guess \( y_1 \).  The next guess is \( {y_2 = x / y_1} \) and the next guess is
\( y_3 = {x / y_2} = {x / (x / y_1)} = y_1 \).  This results in an
infinite loop in which the two guesses \( y_1 \) and \( y_2 \) repeat over and
over, oscillating about the answer.
</p>
<p>One way to control such oscillations is to prevent the guesses from changing so
much.  Since the answer is always between our guess \( y \) and \( {x / y} \), we
can make a new guess that is not as far from \( y \) as \( {x / y} \) by averaging
\( y \) with \( {x / y} \), so that the next guess after \( y \) is 
\( {{1\over2}(y + x / y)} \) 
instead of \( {x / y} \).  The process of making such a sequence of
guesses is simply the process of looking for a fixed point of 
\( y \mapsto {{1\over2}(y + x / y)} \): 
</p>
<div class="lisp">
<pre class="lisp">(define (sqrt x)
  (fixed-point 
   (lambda (y) (average y (/ x y)))
   1.0))
</pre></div>

<p>(Note that \( y = {{1\over2}(y + x / y)} \) is a simple transformation of the
equation \( {y = x / y;} \) to derive it, add \( y \) to both sides of the
equation and divide by 2.)
</p>
<p>With this modification, the square-root procedure works.  In fact, if we
unravel the definitions, we can see that the sequence of approximations to the
square root generated here is precisely the same as the one generated by our
original square-root procedure of <a href="1_002e1.html#g_t1_002e1_002e7">1.1.7</a>.  This approach of
averaging successive approximations to a solution, a technique that we call
<span id="index-average-damping"></span>
<em>average damping</em>, often aids the convergence of fixed-point searches.
</p>
<blockquote>
<p><strong><span id="Exercise-1_002e35"></span>Exercise 1.35:</strong> Show that the golden ratio
\( \varphi \) (<a href="1_002e2.html#g_t1_002e2_002e2">1.2.2</a>) is a fixed point of the transformation 
\( {x \mapsto 1 + 1 / x} \), and use this fact to compute \( \varphi \) by means 
of the <code>fixed-point</code> procedure.
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e36"></span>Exercise 1.36:</strong> Modify <code>fixed-point</code> so that
it prints the sequence of approximations it generates, using the <code>newline</code>
and <code>display</code> primitives shown in <a href="1_002e2.html#Exercise-1_002e22">Exercise 1.22</a>.  Then find a
solution to \( {x^x = 1000} \) by finding a fixed point of \( x \mapsto
{\log(1000) / \log(x)} \).  (Use Scheme&rsquo;s primitive <code>log</code>
procedure, which computes natural logarithms.)  Compare the number of steps
this takes with and without average damping.  (Note that you cannot start
<code>fixed-point</code> with a guess of 1, as this would cause division by
\( {\log(1) = 0} \).)
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e37"></span>Exercise 1.37:</strong> 
</p>
<ol type="a" start="1">
<li> An infinite <span id="index-continued-fraction"></span>
<em>continued fraction</em> is an expression of the form

\[ % :25:
  
f \,=\, {\frac{N_1}{D_1 + \frac{N_2}{D_2 + \frac{N_3}{D_3 + \dots}}}.}
\]

As an example, one can show that the infinite continued fraction expansion with
the \( N_i \) and the \( D_i \) all equal to 1 produces \( {1 / \varphi} \), where
\( \varphi \) is the golden ratio (described in <a href="1_002e2.html#g_t1_002e2_002e2">1.2.2</a>).  One way to
approximate an infinite continued fraction is to truncate the expansion after a
given number of terms.  Such a truncation&mdash;a so-called <span id="index-k_002dterm"></span>
finite continued fraction
<em><i>k</i>-term
finite continued fraction</em>&mdash;has the form

\[ % :26:
  
{\frac{N_1}{D_1 + \frac{N_2}{\ddots + \frac{N_k}{D_k}}}.}
\]

Suppose that <code>n</code> and <code>d</code> are procedures of one argument (the term
index \( i \)) that return the \( N_i \) and \( D_i \) of the terms of the
continued fraction.  Define a procedure <code>cont-frac</code> such that evaluating
<code>(cont-frac n d k)</code> computes the value of the \( k \)-term finite continued
fraction.  Check your procedure by approximating \( {1 / \varphi} \) using

<div class="lisp">
<pre class="lisp">(cont-frac (lambda (i) 1.0)
           (lambda (i) 1.0)
           k)
</pre></div>

<p>for successive values of <code>k</code>.  How large must you make <code>k</code> in order
to get an approximation that is accurate to 4 decimal places?
</p>
</li><li> If your <code>cont-frac</code> procedure generates a recursive process, write one
that generates an iterative process.  If it generates an iterative process,
write one that generates a recursive process.

</li></ol>
</blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e38"></span>Exercise 1.38:</strong> In 1737, the Swiss mathematician
Leonhard Euler published a memoir <cite>De Fractionibus Continuis</cite>, which
included a continued fraction expansion for \( {e - 2} \), where \( e \) is the base
of the natural logarithms.  In this fraction, the \( N_i \) are all 1, and
the \( D_i \) are successively 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, &hellip;.
Write a program that uses your <code>cont-frac</code> procedure from <a href="#Exercise-1_002e37">Exercise 1.37</a> 
to approximate \( e \), based on Euler&rsquo;s expansion.
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e39"></span>Exercise 1.39:</strong> A continued fraction
representation of the tangent function was published in 1770 by the German
mathematician J.H. Lambert:

\[ % :27:
  
{\tan x} \,=\, {\frac{x}{1 - \frac{x^2}{3 - \frac{x^2}{5 - \dots}}}\,,}
\]

where \( x \) is in radians.  Define a procedure <code>(tan-cf x k)</code> that
computes an approximation to the tangent function based on Lambert&rsquo;s formula.
<code>k</code> specifies the number of terms to compute, as in <a href="#Exercise-1_002e37">Exercise 1.37</a>.
</p></blockquote>

<hr>
<span id="g_t1_002e3_002e4"></span><span id="Procedures-as-Returned-Values"></span><h4 class="subsection"><span class="secnum">1.3.4</span><span class="sectitle">Procedures as Returned Values</span></h4>

<p>The above examples demonstrate how the ability to pass procedures as arguments
significantly enhances the expressive power of our programming language.  We
can achieve even more expressive power by creating procedures whose returned
values are themselves procedures.
</p>
<p>We can illustrate this idea by looking again at the fixed-point example
described at the end of <a href="#g_t1_002e3_002e3">1.3.3</a>.  We formulated a new version of
the square-root procedure as a fixed-point search, starting with the
observation that \( \sqrt{x} \) is a fixed-point of the function \( {y \mapsto
x / y} \).  Then we used average damping to make the approximations converge.
Average damping is a useful general technique in itself.  Namely, given a
function \( f \), we consider the function whose value at \( x \) is equal to the
average of \( x \) and \( {f(x)} \).
</p>
<p>We can express the idea of average damping by means of the following procedure:
</p>
<div class="lisp">
<pre class="lisp">(define (average-damp f)
  (lambda (x) 
    (average x (f x))))
</pre></div>

<p><code>Average-damp</code> is a procedure that takes as its argument a procedure
<code>f</code> and returns as its value a procedure (produced by the <code>lambda</code>)
that, when applied to a number <code>x</code>, produces the average of <code>x</code> and
<code>(f x)</code>.  For example, applying <code>average-damp</code> to the <code>square</code>
procedure produces a procedure whose value at some number \( x \) is the average
of \( x \) and \( x^2 \).  Applying this resulting procedure to 10 returns the
average of 10 and 100, or 55:<a class="footnote_link" id="DOCF59" href="#FOOT59"><sup>59</sup></a>
</p>
<div class="lisp">
<pre class="lisp">((average-damp square) 10)
<i>55</i>
</pre></div>

<p>Using <code>average-damp</code>, we can reformulate the square-root procedure as
follows:
</p>
<div class="lisp">
<pre class="lisp">(define (sqrt x)
  (fixed-point 
   (average-damp 
    (lambda (y) (/ x y)))
   1.0))
</pre></div>

<p>Notice how this formulation makes explicit the three ideas in the method:
fixed-point search, average damping, and the function \( {y \mapsto x / y} \).
It is instructive to compare this formulation of the square-root method with
the original version given in <a href="1_002e1.html#g_t1_002e1_002e7">1.1.7</a>.  Bear in mind that these
procedures express the same process, and notice how much clearer the idea
becomes when we express the process in terms of these abstractions.  In
general, there are many ways to formulate a process as a procedure.
Experienced programmers know how to choose procedural formulations that are
particularly perspicuous, and where useful elements of the process are exposed
as separate entities that can be reused in other applications.  As a simple
example of reuse, notice that the cube root of \( x \) is a fixed point of the
function \( {y \mapsto x / y^2} \), so we can immediately generalize our
square-root procedure to one that extracts cube roots:<a class="footnote_link" id="DOCF60" href="#FOOT60"><sup>60</sup></a>
</p>
<div class="lisp">
<pre class="lisp">(define (cube-root x)
  (fixed-point 
   (average-damp 
    (lambda (y) 
      (/ x (square y))))
   1.0))
</pre></div>

<span id="Newton_0027s-method"></span><h4 class="subsubheading">Newton&rsquo;s method</h4>

<p>When we first introduced the square-root procedure, in <a href="1_002e1.html#g_t1_002e1_002e7">1.1.7</a>, we
mentioned that this was a special case of <span id="index-Newton_0027s-method"></span>
<em>Newton&rsquo;s method</em>.  
If \( {x \mapsto g(x)} \) is a differentiable function, then a solution of the equation
\( {g(x) = 0} \) is a fixed point of the function \( {x \mapsto f(x)} \) where

\[ % :28:
  
{f(x)} \,=\, x - \frac{g(x)}{D g(x)}
\]

and \( {Dg(x)} \) is the derivative of \( g \) evaluated at \( x \).  Newton&rsquo;s
method is the use of the fixed-point method we saw above to approximate a
solution of the equation by finding a fixed point of the function
\( {f} \).<a class="footnote_link" id="DOCF61" href="#FOOT61"><sup>61</sup></a>
</p>
<p>For many functions \( g \) and for sufficiently good initial guesses for \( x \),
Newton&rsquo;s method converges very rapidly to a solution of \( {g(x) = 0} \).<a class="footnote_link" id="DOCF62" href="#FOOT62"><sup>62</sup></a>
</p>
<p>In order to implement Newton&rsquo;s method as a procedure, we must first express the
idea of derivative.  Note that &ldquo;derivative,&rdquo; like average damping, is
something that transforms a function into another function.  For instance, the
derivative of the function \( {x \mapsto x^3} \) is the function \( {x \mapsto 3x^2} \).
In general, if \( g \) is a function and \( {dx} \) is a small number,
then the derivative \( {Dg} \) of \( g \) is the function whose value at any
number \( x \) is given (in the limit of small \( {dx} \)) by

\[ % :29:
  
Dg(x) \,=\, {\frac{g(x + dx) - g(x)}{dx}.}
\]

Thus, we can express the idea of derivative (taking \( {dx} \) to be, say,
0.00001) as the procedure
</p>
<div class="lisp">
<pre class="lisp">(define (deriv g)
  (lambda (x)
    (/ (- (g (+ x dx)) (g x))
       dx)))
</pre></div>

<p>along with the definition
</p>
<div class="lisp">
<pre class="lisp">(define dx 0.00001)
</pre></div>

<p>Like <code>average-damp</code>, <code>deriv</code> is a procedure that takes a procedure as
argument and returns a procedure as value.  For example, to approximate the
derivative of \( {x \mapsto x^3} \) at 5 (whose exact value is 75) we can evaluate
</p>
<div class="lisp">
<pre class="lisp">(define (cube x) (* x x x))

((deriv cube) 5)
<i>75.00014999664018</i>
</pre></div>

<p>With the aid of <code>deriv</code>, we can express Newton&rsquo;s method as a fixed-point
process:
</p>
<div class="lisp">
<pre class="lisp">(define (newton-transform g)
  (lambda (x)
    (- x (/ (g x) 
            ((deriv g) x)))))

(define (newtons-method g guess)
  (fixed-point (newton-transform g) 
               guess))
</pre></div>

<p>The <code>newton-transform</code> procedure expresses the formula at the beginning of
this section, and <code>newtons-method</code> is readily defined in terms of this.
It takes as arguments a procedure that computes the function for which we want
to find a zero, together with an initial guess.  For instance, to find the
square root of \( x \), we can use Newton&rsquo;s method to find a zero of the function
\( {y \mapsto y^2 - x} \) starting with an initial guess of 1.<a class="footnote_link" id="DOCF63" href="#FOOT63"><sup>63</sup></a>
</p>
<p>This provides yet another form of the square-root procedure:
</p>
<div class="lisp">
<pre class="lisp">(define (sqrt x)
  (newtons-method 
   (lambda (y) 
     (- (square y) x)) 
   1.0))
</pre></div>

<span id="Abstractions-and-first_002dclass-procedures"></span><h4 class="subsubheading">Abstractions and first-class procedures</h4>

<p>We&rsquo;ve seen two ways to express the square-root computation as an instance of a
more general method, once as a fixed-point search and once using Newton&rsquo;s
method.  Since Newton&rsquo;s method was itself expressed as a fixed-point process,
we actually saw two ways to compute square roots as fixed points.  Each method
begins with a function and finds a fixed point of some transformation of the
function.  We can express this general idea itself as a procedure:
</p>
<div class="lisp">
<pre class="lisp">(define (fixed-point-of-transform 
         g transform guess)
  (fixed-point (transform g) guess))
</pre></div>

<p>This very general procedure takes as its arguments a procedure <code>g</code> that
computes some function, a procedure that transforms <code>g</code>, and an initial
guess.  The returned result is a fixed point of the transformed function.
</p>
<p>Using this abstraction, we can recast the first square-root computation from
this section (where we look for a fixed point of the average-damped version of
\( {y \mapsto x / y} \)) as an instance of this general method:
</p>
<div class="lisp">
<pre class="lisp">(define (sqrt x)
  (fixed-point-of-transform 
   (lambda (y) (/ x y))
   average-damp
   1.0))
</pre></div>

<p>Similarly, we can express the second square-root computation from this section
(an instance of Newton&rsquo;s method that finds a fixed point of the Newton
transform of \( {y \mapsto y^2 - x} \)) as
</p>
<div class="lisp">
<pre class="lisp">(define (sqrt x)
  (fixed-point-of-transform 
   (lambda (y) (- (square y) x))
   newton-transform
   1.0))
</pre></div>

<p>We began section <a href="#g_t1_002e3">1.3</a> with the observation that compound procedures are a
crucial abstraction mechanism, because they permit us to express general
methods of computing as explicit elements in our programming language.  Now
we&rsquo;ve seen how higher-order procedures permit us to manipulate these general
methods to create further abstractions.
</p>
<p>As programmers, we should be alert to opportunities to identify the underlying
abstractions in our programs and to build upon them and generalize them to
create more powerful abstractions.  This is not to say that one should always
write programs in the most abstract way possible; expert programmers know how
to choose the level of abstraction appropriate to their task.  But it is
important to be able to think in terms of these abstractions, so that we can be
ready to apply them in new contexts.  The significance of higher-order
procedures is that they enable us to represent these abstractions explicitly as
elements in our programming language, so that they can be handled just like
other computational elements.
</p>
<p>In general, programming languages impose restrictions on the ways in which
computational elements can be manipulated.  Elements with the fewest
restrictions are said to have <span id="index-first_002dclass"></span>
<em>first-class</em> status.  Some of the
&ldquo;rights and privileges&rdquo; of first-class elements are:<a class="footnote_link" id="DOCF64" href="#FOOT64"><sup>64</sup></a>
</p>
<ul>
<li> They may be named by variables.

</li><li> They may be passed as arguments to procedures.

</li><li> They may be returned as the results of procedures.

</li><li> They may be included in data structures.<a class="footnote_link" id="DOCF65" href="#FOOT65"><sup>65</sup></a>

</li></ul>

<p>Lisp, unlike other common programming languages, awards procedures full
first-class status.  This poses challenges for efficient implementation, but
the resulting gain in expressive power is enormous.<a class="footnote_link" id="DOCF66" href="#FOOT66"><sup>66</sup></a>
</p>
<blockquote>
<p><strong><span id="Exercise-1_002e40"></span>Exercise 1.40:</strong> Define a procedure <code>cubic</code>
that can be used together with the <code>newtons-method</code> procedure in
expressions of the form
</p>
<div class="lisp">
<pre class="lisp">(newtons-method (cubic a b c) 1)
</pre></div>

<p>to approximate zeros of the cubic \( {x^3 + ax^2 + bx + c} \).
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e41"></span>Exercise 1.41:</strong> Define a procedure <code>double</code>
that takes a procedure of one argument as argument and returns a procedure that
applies the original procedure twice.  For example, if <code>inc</code> is a
procedure that adds 1 to its argument, then <code>(double inc)</code> should be a
procedure that adds 2.  What value is returned by
</p>
<div class="lisp">
<pre class="lisp">(((double (double double)) inc) 5)
</pre></div>
</blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e42"></span>Exercise 1.42:</strong> Let \( f \) and \( g \) be two
one-argument functions.  The <span id="index-composition"></span>
<em>composition</em> \( f \) after \( g \) is defined
to be the function \( {x \mapsto f(g(x))} \).  Define a procedure
<code>compose</code> that implements composition.  For example, if <code>inc</code> is a
procedure that adds 1 to its argument,
</p>
<div class="lisp">
<pre class="lisp">((compose square inc) 6)
<i>49</i>
</pre></div>
</blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e43"></span>Exercise 1.43:</strong> If \( f \) is a numerical function
and \( n \) is a positive integer, then we can form the \( n^{\text{th}} \) repeated
application of \( f \), which is defined to be the function whose value at \( x \)
is \( {f(f(\dots (f(x))\dots ))} \).  For example, if \( f \) is the
function \( {x \mapsto x + 1} \), then the \( n^{\text{th}} \) repeated application of \( f \) is
the function \( {x \mapsto x + n} \).  If \( f \) is the operation of squaring a
number, then the \( n^{\text{th}} \) repeated application of \( f \) is the function that
raises its argument to the \( {2^n\text{-th}} \) power.  Write a procedure that takes as
inputs a procedure that computes \( f \) and a positive integer \( n \) and returns
the procedure that computes the \( n^{\text{th}} \) repeated application of \( f \).  Your
procedure should be able to be used as follows:
</p>
<div class="lisp">
<pre class="lisp">((repeated square 2) 5)
<i>625</i>
</pre></div>

<p>Hint: You may find it convenient to use <code>compose</code> from <a href="#Exercise-1_002e42">Exercise 1.42</a>.
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e44"></span>Exercise 1.44:</strong> The idea of <span id="index-smoothing"></span>
<em>smoothing</em> a
function is an important concept in signal processing.  If \( f \) is a function
and \( {dx} \) is some small number, then the smoothed version of \( f \) is the
function whose value at a point \( x \) is the average of \( {f(x - dx)} \), 
\( {f(x)} \), and \( {f(x + dx)} \).  Write a procedure
<code>smooth</code> that takes as input a procedure that computes \( f \) and returns a
procedure that computes the smoothed \( f \).  It is sometimes valuable to
repeatedly smooth a function (that is, smooth the smoothed function, and so on)
to obtain the <span id="index-n_002dfold-smoothed-function"></span>
<em><i>n</i>-fold smoothed function</em>.  Show how to generate
the <i>n</i>-fold smoothed function of any given function using <code>smooth</code> and
<code>repeated</code> from <a href="#Exercise-1_002e43">Exercise 1.43</a>.
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e45"></span>Exercise 1.45:</strong> We saw in <a href="#g_t1_002e3_002e3">1.3.3</a>
that attempting to compute square roots by naively finding a fixed point of
\( {y \mapsto x / y} \) does not converge, and that this can be fixed by average
damping.  The same method works for finding cube roots as fixed points of the
average-damped \( {y \mapsto x / y^2} \).  Unfortunately, the process does not
work for fourth roots&mdash;a single average damp is not enough to make a
fixed-point search for \( {y \mapsto x / y^3} \) converge.  On the other hand, if
we average damp twice (i.e., use the average damp of the average damp of 
\( {y \mapsto x / y^3} \)) the fixed-point search does converge.  Do some experiments
to determine how many average damps are required to compute \( n^{\text{th}} \) roots as a
fixed-point search based upon repeated average damping of \( {y \mapsto x / y^{\kern0.1em n-1}} \).  
Use this to implement a simple procedure for computing
\( n^{\text{th}} \) roots using <code>fixed-point</code>, <code>average-damp</code>, and the
<code>repeated</code> procedure of <a href="#Exercise-1_002e43">Exercise 1.43</a>.  Assume that any arithmetic
operations you need are available as primitives.
</p></blockquote>

<blockquote>
<p><strong><span id="Exercise-1_002e46"></span>Exercise 1.46:</strong> Several of the numerical methods
described in this chapter are instances of an extremely general computational
strategy known as <span id="index-iterative-improvement"></span>
<em>iterative improvement</em>.  Iterative improvement says
that, to compute something, we start with an initial guess for the answer, test
if the guess is good enough, and otherwise improve the guess and continue the
process using the improved guess as the new guess.  Write a procedure
<code>iterative-improve</code> that takes two procedures as arguments: a method for
telling whether a guess is good enough and a method for improving a guess.
<code>Iterative-improve</code> should return as its value a procedure that takes a
guess as argument and keeps improving the guess until it is good enough.
Rewrite the <code>sqrt</code> procedure of <a href="1_002e1.html#g_t1_002e1_002e7">1.1.7</a> and the
<code>fixed-point</code> procedure of <a href="#g_t1_002e3_002e3">1.3.3</a> in terms of
<code>iterative-improve</code>.
</p></blockquote>

<div class="footnote">
<hr>
<h4 class="footnotes-heading">Footnotes</h4>

<div id="FOOT49"><p><a class="footnote_backlink" href="#DOCF49"><sup>49</sup></a>
This series, usually
written in the equivalent form 
\( {\pi\over4} = {1 - {1\over3} + {1\over5}} - {{1\over7} + \dots} \), 
is due to Leibniz.  We&rsquo;ll see how to use this as the basis for some
fancy numerical tricks in <a href="3_002e5.html#g_t3_002e5_002e3">3.5.3</a>.</p>
</div>
<div id="FOOT50"><p><a class="footnote_backlink" href="#DOCF50"><sup>50</sup></a>
Notice that we have
used block structure (<a href="1_002e1.html#g_t1_002e1_002e8">1.1.8</a>) to embed the definitions of
<code>pi-next</code> and <code>pi-term</code> within <code>pi-sum</code>, since these procedures
are unlikely to be useful for any other purpose.  We will see how to get rid of
them altogether in <a href="#g_t1_002e3_002e2">1.3.2</a>.</p>
</div>
<div id="FOOT51"><p><a class="footnote_backlink" href="#DOCF51"><sup>51</sup></a>
The
intent of <a href="#Exercise-1_002e31">Exercise 1.31</a> through <a href="#Exercise-1_002e33">Exercise 1.33</a> is to demonstrate the
expressive power that is attained by using an appropriate abstraction to
consolidate many seemingly disparate operations.  However, though accumulation
and filtering are elegant ideas, our hands are somewhat tied in using them at
this point since we do not yet have data structures to provide suitable means
of combination for these abstractions.  We will return to these ideas in
<a href="2_002e2.html#g_t2_002e2_002e3">2.2.3</a> when we show how to use <span id="index-sequences"></span>
<em>sequences</em> as interfaces
for combining filters and accumulators to build even more powerful
abstractions.  We will see there how these methods really come into their own
as a powerful and elegant approach to designing programs.</p>
</div>
<div id="FOOT52"><p><a class="footnote_backlink" href="#DOCF52"><sup>52</sup></a>
This formula was discovered by the
seventeenth-century English mathematician John Wallis.</p>
</div>
<div id="FOOT53"><p><a class="footnote_backlink" href="#DOCF53"><sup>53</sup></a>
It would be clearer and less intimidating to people learning
Lisp if a name more obvious than <code>lambda</code>, such as <code>make-procedure</code>,
were used.  But the convention is firmly entrenched.  The notation is adopted
from the λ-calculus, a mathematical formalism introduced by the
mathematical logician Alonzo <a href="References.html#Church-_00281941_0029">Church (1941)</a>.  Church developed the 
λ-calculus to provide a rigorous foundation for studying the 
notions of function
and function application.  The λ-calculus has become a basic tool
for mathematical investigations of the semantics of programming languages.</p>
</div>
<div id="FOOT54"><p><a class="footnote_backlink" href="#DOCF54"><sup>54</sup></a>
Understanding
internal definitions well enough to be sure a program means what we intend it
to mean requires a more elaborate model of the evaluation process than we have
presented in this chapter.  The subtleties do not arise with internal
definitions of procedures, however.  We will return to this issue in 
<a href="4_002e1.html#g_t4_002e1_002e6">4.1.6</a>, after we learn more about evaluation.</p>
</div>
<div id="FOOT55"><p><a class="footnote_backlink" href="#DOCF55"><sup>55</sup></a>
We have used 0.001 as a representative &ldquo;small&rdquo; number to
indicate a tolerance for the acceptable error in a calculation.  The
appropriate tolerance for a real calculation depends upon the problem to be
solved and the limitations of the computer and the algorithm.  This is often a
very subtle consideration, requiring help from a numerical analyst or some
other kind of magician.</p>
</div>
<div id="FOOT56"><p><a class="footnote_backlink" href="#DOCF56"><sup>56</sup></a>
This can be accomplished using <code>error</code>, which takes as
arguments a number of items that are printed as error messages.</p>
</div>
<div id="FOOT57"><p><a class="footnote_backlink" href="#DOCF57"><sup>57</sup></a>
Try this
during a boring lecture: Set your calculator to radians mode and then
repeatedly press the <code>cos</code> button until you obtain the fixed point.</p>
</div>
<div id="FOOT58"><p><a class="footnote_backlink" href="#DOCF58"><sup>58</sup></a>
\( \mapsto \) (pronounced &ldquo;maps to&rdquo;) is the mathematician&rsquo;s way of
writing <code>lambda</code>.  \( {y \mapsto x / y} \) means <code>(lambda (y) (/ x y))</code>,
that is, the function whose value at \( y \) is \( {x / y} \).</p>
</div>
<div id="FOOT59"><p><a class="footnote_backlink" href="#DOCF59"><sup>59</sup></a>
Observe that this is a combination whose
operator is itself a combination.  <a href="1_002e1.html#Exercise-1_002e4">Exercise 1.4</a> already demonstrated the
ability to form such combinations, but that was only a toy example.  Here we
begin to see the real need for such combinations&mdash;when applying a procedure
that is obtained as the value returned by a higher-order procedure.</p>
</div>
<div id="FOOT60"><p><a class="footnote_backlink" href="#DOCF60"><sup>60</sup></a>
See
<a href="#Exercise-1_002e45">Exercise 1.45</a> for a further generalization.</p>
</div>
<div id="FOOT61"><p><a class="footnote_backlink" href="#DOCF61"><sup>61</sup></a>
Elementary calculus books usually describe Newton&rsquo;s method in
terms of the sequence of approximations \( x_{n+1} = x_n - {g(x_n)\,/ Dg(x_n)} \). 
Having language for talking about processes and using the idea of fixed points 
simplifies the description of the method.</p>
</div>
<div id="FOOT62"><p><a class="footnote_backlink" href="#DOCF62"><sup>62</sup></a>
Newton&rsquo;s
method does not always converge to an answer, but it can
be shown that in favorable cases each iteration doubles the number-of-digits
accuracy of the approximation to the solution.  In such cases, Newton&rsquo;s method
will converge much more rapidly than the half-interval method.</p>
</div>
<div id="FOOT63"><p><a class="footnote_backlink" href="#DOCF63"><sup>63</sup></a>
For
finding square roots, Newton&rsquo;s method converges rapidly to the correct solution
from any starting point.</p>
</div>
<div id="FOOT64"><p><a class="footnote_backlink" href="#DOCF64"><sup>64</sup></a>
The notion of
first-class status of programming-language elements is due to the British
computer scientist Christopher Strachey (1916-1975).</p>
</div>
<div id="FOOT65"><p><a class="footnote_backlink" href="#DOCF65"><sup>65</sup></a>
We&rsquo;ll see examples of this
after we introduce data structures in <a href="Chapter-2.html">Chapter&nbsp;2<!-- /@w --></a>.</p>
</div>
<div id="FOOT66"><p><a class="footnote_backlink" href="#DOCF66"><sup>66</sup></a>
The major
implementation cost of first-class procedures is that allowing procedures to be
returned as values requires reserving storage for a procedure&rsquo;s free variables
even while the procedure is not executing.  In the Scheme implementation we
will study in <a href="4_002e1.html#g_t4_002e1">4.1</a>, these variables are stored in the procedure&rsquo;s
environment.</p>
</div>
</div>
<hr>
<div class="header">
<p>
Next: <a href="Chapter-2.html" accesskey="n" rel="next">Chapter 2</a>, Previous: <a href="1_002e2.html#g_t1_002e2" accesskey="p" rel="prev">1.2</a>, Up: <a href="#g_t1_002e3" accesskey="u" rel="up">1.3</a> &nbsp; [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Term-Index.html" title="Index" rel="index">Index</a>]</p>
</div>


</section><span class="bottom jump" title="Jump to bottom"><a href="#pagebottom" accesskey="b">&#8675;</a></span><a id="pagebottom"></a>
</body>
</html>
